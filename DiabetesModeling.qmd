---
title: "DiabetesModeling"
format: html
editor: visual
---

```{r}
library(tidyverse)
library(caret)
library(randomForest)
```

## Introduction
```{r}
data <- readRDS("data_factors.rds")
```


### Splitting the Data
We will split the data in a 70/30 split. So, 70 percent of the data in the training set, and 30 percent in the test set. Weâ€™ll use logLoss as our metric to evaluate models. For all model types we will use logLoss with 5 fold cross-validation to select the best model. I will set up my own grid of tuning parameters in any model where that is possible. 

You should research and write up a paragraph about what log loss is and why we may prefer it to things like accuracy when we have a binary response variable.

```{r}
set.seed(558)
# Creating an 70/30 split
split <- createDataPartition(y = data$Diabetes_binaryF, p = 0.7, list = FALSE)
train <- data[split, ]
test <- data[-split, ]
dim(train)
```


## Logistic Regression Models
You should provide a reasonably thorough explanation of what a logistic regression model is and why we apply it to this kind of data. Then you should fit three candidate logistic regression models and choose the best model using CV with log-loss as your metric - lower is better

```{r}
# Model 1
model1 <- Diabetes_binaryF ~ HighBPF + HighCholF + SmokerF

# Model 2
model2 <- Diabetes_binaryF ~ SexF + AgeF + EducationF + IncomeF

# Model 3
model3 <- Diabetes_binaryF ~ HvyAlcoholConsumpF + GenHlthF + PhysHlthF + MentHlthF
```

```{r}
logFit1 <- train(model1, 
              data = train,
              method = "glm",
              metric = "logLoss",
              family = "binomial",
              preProcess = c("center", "scale"),
              trControl = trainControl(method = "cv", 
                                       number = 5,
                                       classProbs = TRUE,
                                       summaryFunction = mnLogLoss))
logFit2 <- train(model2, 
              data = train,
              method = "glm",
              metric = "logLoss",
              family = "binomial",
              preProcess = c("center", "scale"),
              trControl = trainControl(method = "cv", 
                                       number = 5,
                                       classProbs = TRUE,
                                       summaryFunction = mnLogLoss))
logFit3 <- train(model3, 
              data = train,
              method = "glm",
              metric = "logLoss",
              family = "binomial",
              preProcess = c("center", "scale"),
              trControl = trainControl(method = "cv", 
                                       number = 5,
                                       classProbs = TRUE,
                                       summaryFunction = mnLogLoss))
```

```{r}
logFit1$results$logLoss
logFit2$results$logLoss
logFit3$results$logLoss
```

## Classification Tree
You should provide a reasonably thorough explanation of what a classification tree model is and why we might try to use it. Then you should fit a classification tree with varying values for the complexity parameter and choose the best model (best complexity parameter).
```{r}
model <- Diabetes_binaryF ~ HvyAlcoholConsump + HighBP
```


```{r}
treeFit <- train(model, 
              data = train,
              method = "rpart",
              metric = "logLoss",
              trControl = trainControl(method = "cv", 
                                       number = 5,
                                       classProbs = TRUE,
                                       summaryFunction = mnLogLoss),
              tuneGrid = expand.grid(cp = seq(from = 0, to = 0.5, by = 0.01))
              )
```


## Random Forest
You should provide a reasonably thorough explanation of what a random forest is and why we might use it (especially in relation to a basic classification tree). You should then fit a random forest model and choose the best model.
```{r}
rfFit <- train(model, 
              data = train,
              method = "rf",
              metric = "logLoss",
              trControl = trainControl(method = "cv", 
                                       number = 3,
                                       classProbs = TRUE,
                                       summaryFunction = mnLogLoss),
              tuneGrid = data.frame(mtry = 1:2),
              ntree = 100)
```


## Final Model Selection
You should now have three best models (one for each model type above). Now compare all three models on the test set and declare an overall winner
